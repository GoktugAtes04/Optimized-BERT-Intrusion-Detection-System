{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "046vrbEj5dXh"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR_aFcp755Qq",
    "outputId": "a34f16f6-1ef6-44a5-ea7c-d2478076d85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=b06b5e9c43705f55d835229c54ae25e9bd904dd3573a7da51bc38158162bb1b5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil, xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GPUtil-1.4.0 bitsandbytes-0.45.4 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets GPUtil bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngKHOyfBmhye"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score\n",
    ")\n",
    "import psutil\n",
    "import GPUtil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CrsVWYFA2xX"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"HUGGING_FACE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZQoZb_96Cyi"
   },
   "source": [
    "## Network Intrusion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499,
     "referenced_widgets": [
      "9619d5c5234840f3833d052c2e3ed3d7",
      "0bb750052043428794d932a9f733db72",
      "a86d41d991fa4eb1a166021f76b98dcd",
      "bd3a740a4f904b4c848c317b139b0d5b",
      "ceec5bb73c5245ce85e9ee400b14366a",
      "72308dcfdc00437b92820eef9af3e430",
      "f1132dc5b96f48cba647b1ce315d95cd",
      "9bbf50a2b05b4a86ba0b10b708a42a53",
      "a293b1cea0944559a45fadeb95329a54",
      "a591e1ba2a204a659592d3478611b580",
      "e6783a2f55724ee6ab1f68f43872e76e",
      "5d7863c02eae48988dca13b1ec4d0c15",
      "a1efa8f74aa54ff78d5a7a817e158c65",
      "023ba694968e45abafb00abd2a5cd4e6",
      "2937b97011724abe893550ba637004cd",
      "ea7426df86ba492ca3f72697761a98a1",
      "b33edd8dfa1f4f5a845c5f874421c108",
      "d90dcf03847a4dc88ca5a12579a9ab25",
      "00accdb100af43efa4af6b5031e3bcb0",
      "365317ef7b9d44258152ebe29991cd59",
      "3be8b72eec1d439192717b4a4d82b36e",
      "c7f86400066a4e029abe487afd412fa9",
      "74cee0ba74404805aabd3124c4eef80a",
      "feaf8504c45c45b89c36d28cc32d2775",
      "3634bd8647064b1bad7a12ed205c5bd7",
      "08b2d420bd324c60815fda28494e54c1",
      "4b7e613e01414b3486c0c6010c239e4c",
      "0a72961f9ce84c469e9a8b5b9cc99075",
      "92b327fef57b44f3a23b73133d6627fe",
      "1828049fdd834bc387b2eaae69a508a7",
      "b1c2e0e8a4ef4193baed83639133f586",
      "ffc8ee9ee00342e69d43567478735c68",
      "657d6ae08b264acf849183fa649a559a",
      "e79db0eb7b2546f586b2d3498240e173",
      "e7e38b9c9b7b4df696a5bf64ffd0674a",
      "5f85987176f24cbb9a576b70899bc3db",
      "6f85734bbf9f4510b0a4115b45295e13",
      "6933afd93da548bb8112b8ed2a15815a",
      "0687984672f4447aba38548733293642",
      "af60c4c9d9c9410baa7fb7c1744cc14c",
      "c1a3306691d94432be20a9bd6514352c",
      "9c751e9b83de4079951a64df04fd3fa7",
      "7fa6bbdc170e44efabf3cc1a5a578b1d",
      "d466d0a51ec4482c9f36857a01502989",
      "a2efd00f38d242299f95cc1dcb7818b4",
      "33f51dbbb69f43ae932d0f8cd5021493",
      "db8f1de535684a8385a7f1112e5c7920",
      "d343c852a30b45048346db7db34002f1",
      "722329a73c4e457999669271737d75b7",
      "73d63a84a338446d9bfb8d12fd722997",
      "0bee66ef52ba4d82a688a796043fd4a9",
      "bce217dd5596461089b2a8d7aa71305e",
      "bc59330098bf4652b59b2d0e808b003f",
      "25d8905891e54907862937653803a486",
      "d8d65b09ff06408592921f604f506caa",
      "6bbd69dded9d42bb849f60e7f7260c18",
      "5b39b7dd1ae544c6b96ecd590ff55e1c",
      "73f80bea47464ea9912129143f4dce5f",
      "d7f2bceea227491a8c66fd64901ecca4",
      "465af2425f584439819f05d923346961",
      "9427c170547745f8a54f0334015665dc",
      "bb2a1f5bdf2a4e528030f60abbcffa20",
      "2fff158803ff4722a38653b874435cce",
      "16f7e478c9f94f808daf84d8a1639719",
      "3d695ff8a0e14b388c539faa3860441c",
      "43df0053446a4152829a59cf30bcc0c0",
      "30c51eb70e0e421ba380d0369c9e5f39",
      "f563930a3bf64e5792fe7e162fbbac6e",
      "0153eda51f5141bc8e9bdce439130633",
      "303de3687bfb4683a56bd90725e44959",
      "59059a77ca854d2c9a7c51885745abe9",
      "9fbc60b2ec05420eb621bf32f0039120",
      "1fe91f3a1dd8479789bfe84f2e99a8bd",
      "2a50013c99ab4b769b73fde4d01ff39b",
      "c167d007fd3d4b5690b70dff8c18a5e6",
      "57dc9a18f6de4f178aa8cd272d2597cb",
      "044f14638cfb4eceae2cfd6d94d4c0ed",
      "8323feafdbd847c69d631acf82a384b0",
      "057f3ecca2734ac4a8bde1284352606c",
      "7e5152578a52421d92f6f12d463eeb9a",
      "544d36eaf7ba4e7a941b0c83e0a2dd6b",
      "2738e68cabbd4c0385d326325616bf29",
      "cc2e9b642c1e44d4b51378a2a74e101d",
      "ee631788e8e3440180b9c5ce31c2fbba",
      "4bd17e76b59e41e49fd0cba61d4c744b",
      "4b3f8971c44e4c33bb0cab04a1504e38",
      "17249d162f684d32a1b41bb665de3835",
      "0465a2e9b4a245fc883380388ab50489",
      "1da448c7718140919f6c7d00cf068ebf",
      "87046d408447436f8d3903e5e1a21a47",
      "4040f367b11e4dd89376f3d9a60e5b0a",
      "c0cdba7c5d414cf696c62857755cf7ac",
      "c9dd6cb5ecdd4333a10c28d5d2194fdc",
      "7fa6b53490e64687aee2427886edddcb",
      "cb69b37d345d40049fe10db4124d7752",
      "176d6446a2c94c2e9244a5b610bdff9d",
      "04a734b0fe154faca870f084b1910fb9",
      "4b655ea848ab4117bc21843711095593",
      "3162257379c04783b8666fd47e33f1b8",
      "1fe81d38bb704907a99a49f87ef46c29",
      "71c7f627945e40f7b2cbdbd56d9edf37",
      "05509f8c621d4a1e87e01db1b84e3111",
      "64b82b5c92b74a4690bb2861c939bf54",
      "03978aca65914ee5b4b252ff17c075a0",
      "b9b3dea43f704d98988b436624c6afc2",
      "1311e8a66e3a4f90968f6164e704c464",
      "599d08b963b64718a8255f0ed2620809",
      "c0379d2ac0424d59b42179a2eaff7eae",
      "6961a0ea7618485b8502f17061fd02e1",
      "704c23f5b2614eab9fbe4c4607c2afc2",
      "02770073970642b1aa3a0877f06c81b6",
      "80908c0448d44c499ea57ecc48685f3a",
      "98c6ed49b609460ab610296939b9dd76",
      "f4110e53260b4c8184dcacaa2f151d09",
      "0d681e2b825b4a0da18ba68967d04d22",
      "99a29bd991e74db7ada40379ebc9bbe2",
      "8bb3a2f62ddb4a95b01805e049cd81b2",
      "69c866273f85400db9382e317de3f062",
      "4836456fca4e493e8836a152956b084f",
      "8dce9b86bd2549e8b99c2a0f86ab11d1",
      "7eca64b79d9f4581b49b411807537acb"
     ]
    },
    "id": "S_P0Kjo76HZU",
    "outputId": "848315e6-d692-4f83-f9f1-0ba22d64361e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9619d5c5234840f3833d052c2e3ed3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/586 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7863c02eae48988dca13b1ec4d0c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00005.parquet:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cee0ba74404805aabd3124c4eef80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00005.parquet:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79db0eb7b2546f586b2d3498240e173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00005.parquet:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2efd00f38d242299f95cc1dcb7818b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00005.parquet:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbd69dded9d42bb849f60e7f7260c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00005.parquet:   0%|          | 0.00/136M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c51eb70e0e421ba380d0369c9e5f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/145M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8323feafdbd847c69d631acf82a384b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/145M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da448c7718140919f6c7d00cf068ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1187781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe81d38bb704907a99a49f87ef46c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/254525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02770073970642b1aa3a0877f06c81b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/254525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"gates04/network-intrusion-dataset\")\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOU4gj1DRAza"
   },
   "source": [
    "## Teacher Model (DistilBERT) && Student Model (TinyBERT) for Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a4dec721de1543dd9675906204215ae0",
      "81eabf136f9043c2a42f7ffebad1dc3c",
      "0aa254d21751457ea54ac07075598fba",
      "a8e2e87fa7c041e6aae9d26cb30876db",
      "5c9a275b11cb42a4b0e01dedbef5b5e9",
      "3c5cc881cb8a45f08ff9b0c0ce0caad4",
      "9948ec699016406c913c6d1f9645aa2b",
      "da2e35726c7a458d823fa5cd07841b5e",
      "f1f0caf4a6f0422da6c8d33fb4c14fdf",
      "ca3f8e7cbfa94b03896baf6cfcd163df",
      "b8190e192835458a90db28f1e3f94ff9",
      "ac252cccd4b649da8eba69f8ac29fd51",
      "970be0ce31cd49638a3b701d2646440c",
      "0b95f39bded148cda71324107a7fd4d8",
      "1103e620b8d6412cb6900970d76e5f10",
      "8d30a962501f487d8f36d8a5ebf94573",
      "ed685036c3094663931a21b70de32004",
      "08e8bf4928af4dd1a64e4332897d7677",
      "77f94c9cbe4e45cba7f79b339b7ceafd",
      "0ab214e3277446c7a301e3815e3e7111",
      "f47ec375e72d4df6bf15e0e2ccb743a6",
      "f2c2db27cbce4596b5c64e3df63f9398",
      "c37d1bec42e742edb204b01dbb10a8b8",
      "e41560f95b3742daad1256aea481a7a1",
      "5e24c2f7c55848b18d377e61564de531",
      "56718e96a67747f5a759e016adff4ede",
      "880df38c5a06479281d7866affb36eb7",
      "84acd8e0a60d4ec196ba1351c649addf",
      "0f90809905fc4604ba02f8677353e191",
      "687d7032f6af4d7baac73ce98853ef6d",
      "8eff774bda144371abfbec26a2858c95",
      "82c21111508b498d8ff81c0b17992862",
      "8d9ca11082704a11889295cb952c2d60",
      "9b12cf2fb5f642d0bc9dd7ae3fde4a61",
      "f686c6fa002e40d4bcdc4b3da8c08585",
      "5ac5a8d456ee43f896bcbefead129db1",
      "45b7300b1b9f4c5db90ffc111e38a8c4",
      "ec3e236290d44b5fa1cd25e348cbfbbb",
      "4d2202bcb09847b786d60afc7fe3f6e0",
      "3a801bce66034874b52a1ab175b67add",
      "d3fb4fc5fc0e42439d7fa5550b574692",
      "fb54be6699cb4b4283898b6f7832dbd3",
      "1ad314d3dfd34b28be4bdd711f9ec173",
      "1ba1bbc5607444bd9017ab3e76d4ba15",
      "f998cfee25a847c68883d0305f83664a",
      "03f4116484954ec08b2873c409328a90",
      "f17b28e6e39841c4b6d83f49afd6fef6",
      "b509c366230b488b9f4744ffc4d6d57a",
      "89955521e5d94b71b784cf8ed55cde0d",
      "8f029cf25801456aa944378561ebc247",
      "7ec80ff8943a4f3398b238af804e61d9",
      "6cf9f251c91444aeb0c1b7d1694d5c96",
      "d77c2e876bc0473282235d16b82be8bd",
      "0e46e56aa5af42f9bfca3243fd42218f",
      "43f3d6e2234b4666a68fe0b9adb5f339",
      "7ed7fa79e68949648b8c0d4c69589218",
      "cfdbbe4e8b634291a1c82e495adf179b",
      "e0fbcf8e57ea442098c99d9dd70fa2da",
      "4813dd116bbe428b8b5e69b98b0d21a3",
      "2cd1cb8225d641e49727aae88f258844",
      "79d96c47b891480fbc47c9f22ba1681f",
      "6345e544449b447391f5f786083ec0d5",
      "5701b402e659483b8af2aee692f24587",
      "6d4ce47ce37d479aa3b3307fbf2e426b",
      "ac75471211d945ce8cca423e708db69b",
      "190130acd8ad487da7bb4b0e7647115a",
      "4e1dd53cdda8476db8f67b643f560b19",
      "24076b53804e4743968f3186b2c959f0",
      "d6b07bc0a08145c988d80b12373d011d",
      "19c4c5bcbf9c4c7fa652433e6ae96279",
      "2745358b99e5433cb4061714db396222",
      "d4ca8a5e600d41cfb49c47baf227f2f4",
      "40201e3f0cfb4e1dad1ebe7efe5a756d",
      "1d3cf4772baa4844aff29ca3d827b8ab",
      "ce846701f43347f98352736670bddec7",
      "5661cfa2f1214a7c88627b73cb0c0a9f",
      "bb16be6e6a3f483899eea68a882389dd",
      "260847a6db8e4df7b02b8e1a1a4434d5",
      "d617a21e40f7406aa3f492fc41f84665",
      "d9fb8846a52d450190551b58c077552b",
      "49ac09848eb646a5b9619d5ca4d15817",
      "7ba0c652c0ce489f8f1aa4e2109fcbb6",
      "d13ea8dce5ad4e5a800acc736832efb6",
      "cb4cfb5e2bbd4b82846eb63975049fcd",
      "38d61601041047e2a7b4fb77c3df8c4f",
      "a3000073d549426c8b0800d27db287ef",
      "afaf11d12d3d403dbc285fdac7e89bec",
      "bed03c424c614fc89add243c9d3e42f4",
      "ce8f85898ed040799a0c2ba2ee110613",
      "a8b5d2d5903f46699b8d0c4534d744eb",
      "0d7eadbe8ad042fda9f5354c0a6ed8e6",
      "5d8706c37e4e4a9cbea4f3774bba929b",
      "aa0fb369aa1b4da9a5a801c41d9cef0e",
      "711dfcdbc0584a44ba151672bcf38e11",
      "b4d48562625244f4ba2a94eb96d09a55",
      "3e2e1b0c6915480ba6b5e8d7d525ffbf",
      "d8b91d953c734d28a437b7b0ab195df1",
      "0b38ac5b422f4abe9bea7eead4b43f0b",
      "2e1684a9f4a7437bb01785bbcb3b5997",
      "13a684ea05c540bca8fe007512039936",
      "986e80fb60e24476a2569262c308df9a",
      "5a55bff9bf7543bb96d62c310d0c5390",
      "2906055b2c774502a2106c52f8b510a3",
      "83afca55af6f470cbf738ddec6bbcd42",
      "ab6f32cb93e44fd5801b33d0b50823bf",
      "02fa3342d58d4444a09abba5462a9c0f",
      "3ab987dfa15c4af280fad8cd5ba05066",
      "74d4ca249b6c409aa37675abff76ca27",
      "7d765ddc81f9455989f91f5a48beee9d",
      "2573b0a885ca4339b26f09e2ac3ae6cb"
     ]
    },
    "id": "H5bu4D8zRHDq",
    "outputId": "fbb1299f-9741-4fd3-fae2-3623f5967862"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dec721de1543dd9675906204215ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac252cccd4b649da8eba69f8ac29fd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37d1bec42e742edb204b01dbb10a8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b12cf2fb5f642d0bc9dd7ae3fde4a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f998cfee25a847c68883d0305f83664a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed7fa79e68949648b8c0d4c69589218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1dd53cdda8476db8f67b643f560b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260847a6db8e4df7b02b8e1a1a4434d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8f85898ed040799a0c2ba2ee110613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a684ea05c540bca8fe007512039936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (k_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (v_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (out_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=312, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=312, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=312, out_features=312, bias=True)\n",
       "  (classifier): Linear(in_features=312, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "teacher_model_name = \"rdpahalavan/bert-network-packet-flow-header-payload\"\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_model_name)\n",
    "\n",
    "teacher_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher_model.to(device)\n",
    "\n",
    "student_model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
    "student_model = DistilBertForSequenceClassification.from_pretrained(student_model_name, num_labels=24)\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnpugtf_Du8h"
   },
   "source": [
    "## Model for Self Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833,
     "referenced_widgets": [
      "9e7c46bc010e4e9a93b14b9d456b2ba2",
      "0c9d7ba2fbbb43658012e8b54421f8a1",
      "9edbbd59f4c348d29db5bf1aecc1b205",
      "b440b395ba7441d38116907b431a2ec8",
      "d13e289634744a9eb1efbd3dbeb8f69b",
      "0573022580b94c58b25c9bcf747ac282",
      "06d93725609e42b98bfe1455364c8cc1",
      "ad6edf79fc7946f8bc8d67a9dc9291e8",
      "841446a7c350477ca117aceb209a7ca4",
      "99cd95aec5f64930aeab497abe2f2b9c",
      "33a9ba2a691a47f4b3143f9b15aeacff",
      "aa671f89fb0144c2981f88c5d9b8ad99",
      "b65881c535c14248bb27bf37ca1a0860",
      "bcb6f5b6e14542e1a25b91b890fb32ac",
      "5642356e1e704e53b561544b310286f6",
      "d8c18e1bf52e47aab9a3491d049aeb4a",
      "e35620dec69444ad9684c8dd7c19e4ae",
      "7796040666ce4c56905f399f769710d8",
      "5d650b110741490cae012e1584ba7bc9",
      "a2d37c7f64c44f358ec3d82b8c9f9153",
      "43a84e6b42834f91a4f5b807253fc2c3",
      "f9b8c5fb2c2144c6b0ee54781abeb2bf",
      "87ff374c610e469eb33c7a9e89cd7fdc",
      "6faa170fd75b49fdb94c75ccf2758d9d",
      "7e4ba2321b45445e82ae5a85b4aa8d6d",
      "fa1356e9f550445a89d8d52abea915cc",
      "47e20d2d7603414cb5751be93f735680",
      "d2b250e7cae04657b06022aadd6fc2dc",
      "91128cb29b6c43299c27cea6be037c2f",
      "06eb8b086c3a4f54a90aa32fb9fc3baa",
      "32f624b57f174df7841f965cd8b75238",
      "0308744c0fb74e70bb0a51cb8c7582e3",
      "d819f8734c21481cbd0e17cd3d4a6b5a",
      "cb795bbab8534d5cad0d2e280c23c4be",
      "0174d0e93077456f86e09685e8e6de86",
      "ea5699f8c31e46f89493a4926c99f495",
      "b97d6946e1684883a5caafa35210bd59",
      "81fa43b32f884e78b65b52cb743f7c22",
      "b0d242f0abb540db94dd0fb832275320",
      "3201693abd554901874699050a9f75b2",
      "2a8bf3917332459bac02ff33f5c97df6",
      "6d6a7b6aecc141d0b3ba0854209e1502",
      "8e55a17dc41f439c97789682c8186b05",
      "3f0c43dda97c4ce4adc481a53c7dc500",
      "e940c95bc51242fcaa3962c14ae215e5",
      "c5b3fc1388b14b6098ea60424bf0fa4f",
      "9e9a0d94a2014fd6905fe4105aa3694f",
      "00134582ebb44191b020f30c35db899f",
      "02ac2e2f2819492085f9ad00c5963cfc",
      "6a86b81ee70f4cbba947ebaf7ae1c882",
      "826ae8b159734ebf95e24414349a4e70",
      "15cce6f7a92f4b908800f7509825bb4a",
      "5930a190c3e74752b801bd7b52dd4088",
      "9fc40304e60d4e9fa2e02263ebd7e0bb",
      "db07d49af4e244e680dbf22b89e6323e",
      "9987ca5ba3934dad88c72c4008ab05ca",
      "0f4acdcd2b69474cb11d7198e2c0ffd9",
      "aae5487adb5941889b65432177503835",
      "2b13f2996f4a4fe685ee599163f172e2",
      "2710ba5be70646418e8696f2e2e84357",
      "276c694684b64c24b732937843e4f0c3",
      "570621e505ec430ebff9527ab0634872",
      "2cfc54cf09ab407ea58699b8e7eaf8e6",
      "462544a641c8473a8d758768c95141ca",
      "edd87fa7cc6e4bc99366480d1e356596",
      "274bee7be30d44338e4737efd5df4cd3"
     ]
    },
    "id": "gUE29LI9Dzuy",
    "outputId": "cf6b33fb-0719-4d7a-deed-a52429cc63e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7c46bc010e4e9a93b14b9d456b2ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa671f89fb0144c2981f88c5d9b8ad99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ff374c610e469eb33c7a9e89cd7fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb795bbab8534d5cad0d2e280c23c4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e940c95bc51242fcaa3962c14ae215e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9987ca5ba3934dad88c72c4008ab05ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/76.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (k_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (v_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (out_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=312, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=312, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=312, out_features=312, bias=True)\n",
       "  (classifier): Linear(in_features=312, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "model_name = \"gates04/FP16-KD-NID\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "labels = [\n",
    "    'Analysis', 'Backdoor', 'Bot', 'DDoS', 'DoS', 'DoS GoldenEye',\n",
    "    'DoS Hulk', 'DoS SlowHTTPTest', 'DoS Slowloris', 'Exploits',\n",
    "    'FTP Patator', 'Fuzzers', 'Generic', 'Heartbleed', 'Infiltration',\n",
    "    'Normal', 'Port Scan', 'Reconnaissance', 'SSH Patator',\n",
    "    'Shellcode', 'Web Attack - Brute Force', 'Web Attack - SQL Injection',\n",
    "    'Web Attack - XSS', 'Worms'\n",
    "]\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833,
     "referenced_widgets": [
      "3f574f368ea6413ba6ab16182e2d84f6",
      "ac81dd0db6b14d6089d0389455b11261",
      "c7a36161dff94e1ab3e95db2fe92542b",
      "a12e185f8f5645c29146e66d322ec9ce",
      "31a2d1cd27614c92926f41951efa26d1",
      "46386d5aa7304c25acf0b1562c65ed6d",
      "7b468d49a57c4d269fa52b690b7fe53c",
      "dd9bafe197b64cf182e49cc203d8f087",
      "3cea2435fef941168070fc990824beff",
      "80817ec612d54d4eb35349c8ebc1d771",
      "705a944c22934b868cc3f84f6923f448",
      "6fba09c025b04968bc5da8ccf5e417cc",
      "0891dfd85dc14128a91fe8902fa8f2d0",
      "5f8cd6b0f1b7417bad74e1723a81a490",
      "4fce0fdfc38749258ce00b8cf0e5eccb",
      "018c057ba94d43b5892cac868804977a",
      "08e36d3111e74495967432bde710495a",
      "1c45be1107e04b41aef85a6cea1fb170",
      "a1da5163fb724b80948beea475920cac",
      "5fb9b85c4f994d7eb27b16a507a2bada",
      "f1fe1c68fcf948609f2bca18a7a97ac6",
      "beb8f429ff6745e7b9264222960d6264",
      "55142254385e4e9aae91de1b2cde0288",
      "83b19e17d14b42fbab91b98d59d108d3",
      "ac80991177d84496959366424c6f0f09",
      "9fa51afb5f5145ddac64f1c25130c87c",
      "b5a0f320a92d41c69e970759865838ae",
      "a8456e0f5c114c50819899feac1a6b36",
      "b0ee588ce24c4b7f802ae4addbc9c57b",
      "74460e81dc844d8babd1b79654fc179c",
      "bf49cdb6b0194957a9be8cb7af3a43f3",
      "d37baa66b90047a0b49f9d3794690aea",
      "b19635450ac04728b55556e1c0356694",
      "dcc72b3f927d4685817391b64f2bff72",
      "651fe45630584ad994ae72ed029e70e4",
      "cf4c66febbe74be7a8494cc3ffbdc287",
      "c672ed27c36e4a08aed404649cb0ee1e",
      "804aed7d3f074354aabcc67ae091d05f",
      "ef2f0187a6954d8d95a67ec72a3d08d9",
      "ce2615a63d884d3b8d13d31449471e2c",
      "2bbd4c463acf40cb9f85fa651fc019df",
      "cb5fc50fb0cb4f38b8079184f8a16145",
      "cea02b857e794da69a996472b9c07aec",
      "95659b1e5ebb419cb8b0586d90149b11",
      "dc0d95533a29447fa2d691b370aabff8",
      "8bae39a851ad470bb4909b477ab93ec1",
      "f55861f8f1574d3ba8d405c1b71773f1",
      "63623586e21346d7a6a7811964a18584",
      "2413e8620c574b56b076f5d3a73d61a6",
      "0c509ccaac6b42bfa69a98a57ae1214d",
      "c8096d3e9dc04ce49b532ba17ad095ca",
      "0e548739225444809e2453b513e4e61a",
      "4efe2f8719f241a9bfd805f2ee6efd78",
      "7bb204c5ef9e4019a12a0cfc79555573",
      "92836cb0e93143f88b04800b3a6a9ef1",
      "cc608e3a484c4315a0b1d94a73256108",
      "d76f3fdbaaa44443b3f7b1ddabc8e4f5",
      "bd8287544aa146f2885979daad6728ed",
      "0b77bbf26c77484cb450e0b93fc44514",
      "e99bd59aed234d30aaae870b12229a35",
      "7f04d782786147eda444cd1884b44605",
      "d23699d6bd4b49dfbcddab499d9edbfe",
      "b7645e6ca6654386b738da17d4dfd5e8",
      "c93f674732bd4e2282b1248247c0252e",
      "f2ea120332de458299851a68a5abaf57",
      "35edefecb3834e469379388fe1ddb9e2"
     ]
    },
    "id": "qunsNbC6rBc0",
    "outputId": "5ae8760a-592a-4993-ddf3-37931e9666fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f574f368ea6413ba6ab16182e2d84f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fba09c025b04968bc5da8ccf5e417cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55142254385e4e9aae91de1b2cde0288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc72b3f927d4685817391b64f2bff72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0d95533a29447fa2d691b370aabff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc608e3a484c4315a0b1d94a73256108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/76.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (k_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (v_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (out_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=312, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=312, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=312, out_features=312, bias=True)\n",
       "  (classifier): Linear(in_features=312, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "model_name = \"gates04/Structured-FP16-KD-NID\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "labels = [\n",
    "    'Analysis', 'Backdoor', 'Bot', 'DDoS', 'DoS', 'DoS GoldenEye',\n",
    "    'DoS Hulk', 'DoS SlowHTTPTest', 'DoS Slowloris', 'Exploits',\n",
    "    'FTP Patator', 'Fuzzers', 'Generic', 'Heartbleed', 'Infiltration',\n",
    "    'Normal', 'Port Scan', 'Reconnaissance', 'SSH Patator',\n",
    "    'Shellcode', 'Web Attack - Brute Force', 'Web Attack - SQL Injection',\n",
    "    'Web Attack - XSS', 'Worms'\n",
    "]\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833,
     "referenced_widgets": [
      "7dc3b96a85f84671a6212f9baf827ac5",
      "4b2463607e254139bd1b32d12556dbf2",
      "49c5e4b6300e43468d87a7bc8d05501c",
      "749f3931ab41423ca04496ded366adbe",
      "b0b6261294714aba9db81a9015f03cb2",
      "314c30588ee141d7bf0c25e8dbf380f7",
      "859c55eb05254a369a206a7f8c028685",
      "e9f7237cfab0406cbdfeb93406516927",
      "5de1b030029745c9a1302b63c6426886",
      "fbb8f150a1374ab5885addef8bf877b3",
      "a414cbb044d049cbb8d626c9ab17747a",
      "d885946f95d6408e9d5b51e78c3aa4fb",
      "9277c26ee83c4c5a8a5332f20c06901c",
      "39e3227e9f3f4c7c9d6ae53c0370b47f",
      "dada5898716e45deb4cecaf6731160b3",
      "f959cda3359f4115abeff6592829d0e3",
      "4671ae11ce324a19be38cdbcaf2af22c",
      "9f0de69cfb0349e0ababccc94041b855",
      "588857d68db24ce1a240dc51bcb09a18",
      "95f0b00ea14e4c38bc8f190223858985",
      "bb9b9124a5b64a6788d7de012bcc0d59",
      "5b3a9eb7577f494aa5fc670f94cb49e4",
      "88f9254e3ee84183b5d9afe7bb1571cf",
      "5545285038b4494e8b229276a00f7140",
      "ed6710d3dda54e37924b7b5ea2794827",
      "5a0b5966c2214bcb8a18a0a131647d0c",
      "bfff787933bb48488be6aa2e2fb51e09",
      "4e537bf19a384a79a6717948552fb781",
      "374a36ae747244a7aebe1291fbc8f538",
      "e3b3b64e0b384f5098644fc2947d62f8",
      "124fc08055eb4635bcdee1cc815f665f",
      "fe80052e9903472aaf4c365e8b7f1f16",
      "6838d359008549b5a63bfb6c84c11183",
      "3774183279d0414ea001f199ef944e04",
      "225cc309f848425baf5c1b1b2eb5210a",
      "2a58b2031a944f89bf3344d0f0af9360",
      "b3fbff21f3354823acf3056a37c20034",
      "99afb09c24c14673a5c71af586217c9a",
      "d29cfdb449274448802e64efca24ff86",
      "e35b30a5bb48474dab67b47c51a1a313",
      "7be558e586c04b5bbf875653a3793464",
      "333b64ac2fa847b6a4e6a839e935c5e8",
      "dc254533cce44584bbd90a208a712589",
      "fd5232583a1742a39f44bb0959a06795",
      "bd38cbd48b0345c690f943122f3b9f94",
      "2259cfc3c3734ad59a4c9a110f784968",
      "014d60951759487ab88034aeaa501ea4",
      "d4fd77edab0d4fd68d44b96678239bf7",
      "b5644ecacdb04667800c7deda54de772",
      "d71957abf7fc4eb7946c82d98f40797e",
      "450ae5e563244570b3f2f6e02620a7a3",
      "e0deee1985cf479fa88a50fd4e5efd68",
      "1ee62eda324c4231bd3e2fb64aaf39e9",
      "b43c6627d9144ae5ac4bb2f243d7f138",
      "7e242a4a7cf047d6acf9146d955a32c6",
      "3bf1dffee7824a15a6de8f75aa0d8033",
      "a737c87161fc4548be2c2941df4b72c9",
      "f5448bb72cdf459fb5420a1d6ee549c5",
      "f1f1edcef0b0491a82f46a44a6faef9e",
      "55dbccd68f8e4fee9a1b77fa89f910d2",
      "bfb16811b00f4cd7ba1509ecabc96cdf",
      "8ce62fbe45cf401e98dcc6f12332e3d7",
      "33cb77de7abe4eeab1610f8bef64ec6c",
      "a046fcb7d0334928bfd0d33ed1f6b345",
      "81704d0af7234ffabbd15970c4b79993",
      "9ae9ca318c6a4dd2a2fa1e417638766a"
     ]
    },
    "id": "It0GBq9YSvjK",
    "outputId": "6fd7e365-c7d3-469c-bd7d-3771b7708940"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc3b96a85f84671a6212f9baf827ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d885946f95d6408e9d5b51e78c3aa4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f9254e3ee84183b5d9afe7bb1571cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3774183279d0414ea001f199ef944e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd38cbd48b0345c690f943122f3b9f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf1dffee7824a15a6de8f75aa0d8033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/76.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (k_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (v_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (out_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=312, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=312, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=312, out_features=312, bias=True)\n",
       "  (classifier): Linear(in_features=312, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "model_name = \"gates04/Structured-NF4-KD-NID\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "labels = [\n",
    "    'Analysis', 'Backdoor', 'Bot', 'DDoS', 'DoS', 'DoS GoldenEye',\n",
    "    'DoS Hulk', 'DoS SlowHTTPTest', 'DoS Slowloris', 'Exploits',\n",
    "    'FTP Patator', 'Fuzzers', 'Generic', 'Heartbleed', 'Infiltration',\n",
    "    'Normal', 'Port Scan', 'Reconnaissance', 'SSH Patator',\n",
    "    'Shellcode', 'Web Attack - Brute Force', 'Web Attack - SQL Injection',\n",
    "    'Web Attack - XSS', 'Worms'\n",
    "]\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833,
     "referenced_widgets": [
      "46f9d9836bc040aa86800ec6ddd0860e",
      "2ef275d82083494baaab175254bf2788",
      "e121ccb245964dd39a83939a2362a862",
      "b66889b297514450844fe4d21e5cc590",
      "babee24fd8d24511a551a29c73702543",
      "8ca532d8bce34df6b46a8da0fa90ba76",
      "5a3f0c09e3f240109e5f2309dcd70a07",
      "f88721611a5c4fe08dff278fc1271efd",
      "328008a56a064191a8fdafbb2e0ecef2",
      "148bd9854488480fa6ff1a57bd36c969",
      "5b258ed9ec88431e8939d77354963fe6",
      "3899f3fac76042b8b6aa6fd10190d931",
      "1d0991778d134e209f80c0dff3093da6",
      "36736823d5554a5986c235e173909ce1",
      "d1e2f3852df449cb9707b81e093a56cd",
      "621bfdf368a047b8b2277162eb1926b7",
      "2d79db2855bd434a839199e824548c66",
      "4cba620c1c854b6aae31f727906e2679",
      "c3c7248ce42c411a9071918d7ac66f2b",
      "2cc1e4a6a8494b9dada1364febbc03de",
      "44a15fec458846e6b7ecde38b669bd81",
      "38576f49b3d6422992fa8e2f6287a1fe",
      "02835cab0f4b4ca89933a9c5f2ea9f53",
      "a299ac8d520c40ee8c06448b4eeeca62",
      "ca98b06d94644b5999bfdcd8b1770f07",
      "b35551084c04451ba6d096b55d17591c",
      "87eb54971b8748b59db1ff14303f4797",
      "208a44d231544b60ac40ef095c3cca31",
      "2294854d278946c380573e52b43f1e02",
      "76d3a26de467403f998dbbaff4f480d6",
      "0e70a4ea98b84ebf84bfb0d459499f26",
      "58d941e2be8f4ec2a1f35589c5836e52",
      "2b453c044918475b9a2a09cc9f8391b2",
      "dc5d2bcdf1ae482a95d69b6e8f68e985",
      "e5c8911b44d943e0a2db3d3a8eabb037",
      "a7af11abf0b149e3834e0709dd3af1a1",
      "8bfba9ee84044923840508d9109783fe",
      "8af4a05873474028a94ef5d4e08f1c39",
      "00415db1f8594a68bff4f2d28e94cf17",
      "2366cf91ea734b78a04984a93c2900f6",
      "69c91486df9d40018e1379f31a83c0c1",
      "f51e8fd531e1448ca8558a4d5255a9a2",
      "30c1134820364feea1d69a1f2d5de56d",
      "d89a8c6018df4acbb4b4efc3e86b9596",
      "8027a5afedb8488dbe49a94474807902",
      "821f1bb8acb142519d581d5783e410dc",
      "2a99655d78dd4c73b4bacf201e2251c8",
      "74be9638f1cd4caaae6400ae1ee4e361",
      "466629743e6245e08dd8302c230150f1",
      "f94980b11511402eb66e0c354ae5cbea",
      "848e2d96c475471d9b0bde68b081e926",
      "c1978e51f19a4760adba97044a22b965",
      "21c81a02c10e46afb2591f95b2730d44",
      "35c85ad465aa47e399de9e30aee15139",
      "3689b3b8089d4f0987a3eda540278a6d",
      "083322c9197d4440bb21186ffb3bc6cf",
      "0ef864da82524aa5aba2718565230feb",
      "930f71dc08cf407382d44c94c37d76a7",
      "b81107ac4e00462db346215dad289234",
      "2fb8b9b99822420aae828bd1e6bce0b6",
      "7d288beee90f4786894409ab899d1244",
      "babce26f56b7474293563a0c804e2d2f",
      "19f88f8ffb4c416b891a2948949beb4a",
      "992a9c6576854b36bb690611849d720b",
      "c6f921f580b94f37b0d7a09ede28c49b",
      "c29febeb96154840bbbff34e2cc53298"
     ]
    },
    "id": "WCBd1tQjop8d",
    "outputId": "2a2823df-bec9-4601-e866-08fbae98d91f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f9d9836bc040aa86800ec6ddd0860e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3899f3fac76042b8b6aa6fd10190d931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02835cab0f4b4ca89933a9c5f2ea9f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5d2bcdf1ae482a95d69b6e8f68e985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8027a5afedb8488dbe49a94474807902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083322c9197d4440bb21186ffb3bc6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/76.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (k_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (v_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (out_lin): Linear(in_features=312, out_features=312, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=312, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=312, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=312, out_features=312, bias=True)\n",
       "  (classifier): Linear(in_features=312, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "model_name = \"gates04/Structured-FP16-KD-SD-NID\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "labels = [\n",
    "    'Analysis', 'Backdoor', 'Bot', 'DDoS', 'DoS', 'DoS GoldenEye',\n",
    "    'DoS Hulk', 'DoS SlowHTTPTest', 'DoS Slowloris', 'Exploits',\n",
    "    'FTP Patator', 'Fuzzers', 'Generic', 'Heartbleed', 'Infiltration',\n",
    "    'Normal', 'Port Scan', 'Reconnaissance', 'SSH Patator',\n",
    "    'Shellcode', 'Web Attack - Brute Force', 'Web Attack - SQL Injection',\n",
    "    'Web Attack - XSS', 'Worms'\n",
    "]\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MDFCXC0TXqN"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcWhnGnkYu5d",
    "outputId": "6a1fab80-9083-4c5f-c3fc-d2c09c7ae062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Analysis': 0, 'Backdoor': 1, 'Bot': 2, 'DDoS': 3, 'DoS': 4, 'DoS GoldenEye': 5, 'DoS Hulk': 6, 'DoS SlowHTTPTest': 7, 'DoS Slowloris': 8, 'Exploits': 9, 'FTP Patator': 10, 'Fuzzers': 11, 'Generic': 12, 'Heartbleed': 13, 'Infiltration': 14, 'Normal': 15, 'Port Scan': 16, 'Reconnaissance': 17, 'SSH Patator': 18, 'Shellcode': 19, 'Web Attack - Brute Force': 20, 'Web Attack - SQL Injection': 21, 'Web Attack - XSS': 22, 'Worms': 23}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "if hasattr(config, \"label2id\"):\n",
    "    label_mapping = config.label2id\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "else:\n",
    "    label_mapping = {\"Normal\": 0, \"DoS\": 1, \"Probe\": 2, \"U2R\": 3, \"R2L\": 4}  # Örnek!\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "print(\"Label Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "04291800ff7742659af7ba3264eeafe6",
      "5012c11feaaf42a59d042712e0c22a28",
      "81549d5746fe46b3a4fcce56671216d0",
      "4e22558b35af44b4ac9f23ab5f3f4541",
      "6bde94494a3d47f08cd7aed5532ae237",
      "0edd9eeb75154afca9a84fd835bd3999",
      "e491d5ade0a949aeb3cccb9f75f1932a",
      "322dd86a35b14a7ebb30524c4c1d4811",
      "f10072bfcbf044b0bc4e8d027312f6ca",
      "369d304bece547ddb0f28cf4af26e848",
      "74e88b5a2af0435b931c222acb6a6f8e",
      "2b9cb759bdb8411fbddd1d1b6f2d8774",
      "48945b7d92064e44b134fb60add6238b",
      "ff5c82c7094f4caabd83e5f0c726b3f5",
      "3b0063e31a9e476d9c917c8b3cedac99",
      "3a65934325b647aebd14156eaad2cbb7",
      "1fd2c898daf643cb813fe529eb567ea1",
      "89de84eefeed4eb58737350c18169b7f",
      "91de938b056543229344c8d2a82b42e7",
      "e3f646024653430a99a4ecbdbae1cfe7",
      "5419e1db8e8e43eab7d100fee77588fa",
      "074cc6e5c0474aa1a94feb148ab4303b",
      "03390fd67f6f4505a730707426c4decc",
      "215de8ceab5344ff98838bac0828dc83",
      "bf384339243c4130b31a09c1fe875156",
      "0be5ba8d236a419c8982025c04f31f44",
      "9ba77d411b934e1fb5ded93d7c6bfae4",
      "9f9f7bcb6507496c93cc3826ea0d6311",
      "2d5bf03d574a4450bdf8340b33a0db35",
      "029dec00e01f4c6ca391769220c00042",
      "f8893b2e25a84c50a957cee3e0269265",
      "fab9e0721f994d408f63cc552b51db8d",
      "44d18e6e352040a28140414c900bddb5"
     ]
    },
    "id": "UAV3WNnbTcUE",
    "outputId": "4db8e477-257e-468a-b9b6-c6425785b9db"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04291800ff7742659af7ba3264eeafe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/1187781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9cb759bdb8411fbddd1d1b6f2d8774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/254525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03390fd67f6f4505a730707426c4decc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/254525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 512\n",
    "\n",
    "def tokenize_dataset(examples):\n",
    "    texts = examples[\"packet_dat\"]\n",
    "    tokenized_inputs = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "    tokenized_inputs[\"labels\"] = [label_mapping[label] for label in examples[\"attack_cat\"]]\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "train_encoded = train_dataset.map(tokenize_dataset, batched=True, num_proc=16)\n",
    "val_encoded   = validation_dataset.map(tokenize_dataset, batched=True, num_proc=16)\n",
    "test_encoded  = test_dataset.map(tokenize_dataset, batched=True, num_proc=16)\n",
    "\n",
    "train_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "train_encoded = train_encoded.remove_columns([\"packet_dat\", \"attack_cat\"])\n",
    "val_encoded = val_encoded.remove_columns([\"packet_dat\", \"attack_cat\"])\n",
    "test_encoded = test_encoded.remove_columns([\"packet_dat\", \"attack_cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhp8FW9yV_Vb"
   },
   "source": [
    "## Knowledge Distillation Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYWMr2etWC3t"
   },
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, labels, alpha=0.5, temperature=2.0):\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()(student_logits, labels)\n",
    "\n",
    "    t_logits = teacher_logits / temperature\n",
    "    s_logits = student_logits / temperature\n",
    "\n",
    "    teacher_probs = F.softmax(t_logits, dim=-1)\n",
    "    student_log_probs = F.log_softmax(s_logits, dim=-1)\n",
    "\n",
    "    kld_loss = F.kl_div(student_log_probs, teacher_probs, reduction=\"batchmean\") * (temperature**2)\n",
    "    return alpha * kld_loss + (1.0 - alpha) * ce_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJLC2uTeVqt4"
   },
   "source": [
    "## Knowledge Distillation Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khDguqznVs52"
   },
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, teacher_model, alpha=0.5, temperature=2.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.teacher_model.eval()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "\n",
    "        # Student forward pass\n",
    "        outputs_student = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"]\n",
    "        )\n",
    "        student_logits = outputs_student.logits\n",
    "\n",
    "        # Teacher forward pass (no grad)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher_model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"]\n",
    "            )\n",
    "        teacher_logits = outputs_teacher.logits\n",
    "\n",
    "        # Distillation\n",
    "        loss = distillation_loss(\n",
    "            student_logits=student_logits,\n",
    "            teacher_logits=teacher_logits,\n",
    "            labels=labels,\n",
    "            alpha=self.alpha,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        return (loss, outputs_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wurGDv3Bcak"
   },
   "source": [
    "## Self Distillation Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pX5rdLY8BfYb"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class SelfDistillationTrainer(Trainer):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        alpha=0.5,\n",
    "        temperature=2.0,\n",
    "        use_ema_teacher=True,\n",
    "        ema_decay=0.995,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(model, *args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.use_ema_teacher = use_ema_teacher\n",
    "        self.ema_decay = ema_decay\n",
    "\n",
    "        self.teacher_model = copy.deepcopy(model)\n",
    "        self.teacher_model.eval()\n",
    "\n",
    "    def ema_update(self):\n",
    "\n",
    "        for teacher_param, student_param in zip(self.teacher_model.parameters(), self.model.parameters()):\n",
    "            teacher_param.data = self.ema_decay * teacher_param.data + (1.0 - self.ema_decay) * student_param.data\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "\n",
    "        # Student forward\n",
    "        outputs_student = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"]\n",
    "        )\n",
    "        student_logits = outputs_student.logits\n",
    "\n",
    "        # Teacher forward (no grad)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher_model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"]\n",
    "            )\n",
    "        teacher_logits = outputs_teacher.logits\n",
    "\n",
    "        # Distillation loss\n",
    "        loss = distillation_loss(\n",
    "            student_logits=student_logits,\n",
    "            teacher_logits=teacher_logits,\n",
    "            labels=labels,\n",
    "            alpha=self.alpha,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "\n",
    "        return (loss, outputs_student) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, *args, **kwargs):\n",
    "\n",
    "        loss = super().training_step(*args, **kwargs)\n",
    "        if self.use_ema_teacher:\n",
    "            self.ema_update()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VUzVDy4WGzj"
   },
   "source": [
    "## System Metrics Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS_oYFp2WMI5"
   },
   "outputs": [],
   "source": [
    "class SystemMetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.steps = []\n",
    "        self.cpu_usage = []\n",
    "        self.gpu_usage = []\n",
    "        self.gpu_mem = []\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.steps.append(state.global_step)\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        self.cpu_usage.append(cpu_percent)\n",
    "\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if gpus:\n",
    "            gpu = gpus[0]\n",
    "            self.gpu_usage.append(gpu.load * 100.0)\n",
    "            self.gpu_mem.append(gpu.memoryUsed)\n",
    "        else:\n",
    "            self.gpu_usage.append(0.0)\n",
    "            self.gpu_mem.append(0.0)\n",
    "\n",
    "    def plot_system_metrics(self):\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(self.steps, self.cpu_usage, label=\"CPU Usage (%)\", color=\"blue\")\n",
    "        plt.plot(self.steps, self.gpu_usage, label=\"GPU Usage (%)\", color=\"red\")\n",
    "        plt.xlabel(\"Global Step\")\n",
    "        plt.ylabel(\"Usage (%)\")\n",
    "        plt.title(\"CPU and GPU Usage During Training\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(self.steps, self.gpu_mem, label=\"GPU Memory (MB)\", color=\"green\")\n",
    "        plt.xlabel(\"Global Step\")\n",
    "        plt.ylabel(\"Memory (MB)\")\n",
    "        plt.title(\"GPU Memory Usage During Training\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WffSNipWQoH"
   },
   "source": [
    "## Loss Metrics Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMBVdEiCWX_O"
   },
   "outputs": [],
   "source": [
    "class LossMetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_loss = []\n",
    "        self.eval_loss = []\n",
    "        self.steps = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if \"loss\" in logs:\n",
    "                self.train_loss.append(logs[\"loss\"])\n",
    "                self.steps.append(state.global_step)\n",
    "            if \"eval_loss\" in logs:\n",
    "                self.eval_loss.append(logs[\"eval_loss\"])\n",
    "\n",
    "    def plot_loss_curves(self):\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(self.steps, self.train_loss, label=\"Train Loss\", marker=\"o\")\n",
    "\n",
    "        eval_x = self.steps[:len(self.eval_loss)]\n",
    "        plt.plot(eval_x, self.eval_loss, label=\"Eval Loss\", marker=\"x\")\n",
    "\n",
    "        plt.xlabel(\"Global Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training & Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1MUXu8pWdPt"
   },
   "source": [
    "## Callbacks Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoToY7NhWm2S"
   },
   "outputs": [],
   "source": [
    "system_metrics_callback = SystemMetricsCallback()\n",
    "loss_metrics_callback   = LossMetricsCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4T1mdWLWqzb"
   },
   "source": [
    "## Training Arguments for Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGK_he1TWuQx",
    "outputId": "5b94eeef-02c3-4ad5-cedf-55ff0292c38e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./Structured-NF4-KD-NID\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=650,\n",
    "    per_device_eval_batch_size=650,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=64,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"F1 score\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",  # no wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0gAL1SHB_nO"
   },
   "source": [
    "## Training Arguments for Self Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYRSS-xbCEYZ",
    "outputId": "1b52957f-3c43-4a30-da17-5ef82aacce82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./Structured-FP16-KD-SD-new-NID\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=300,\n",
    "        per_device_eval_batch_size=300,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        fp16=True,  # Mixed precision\n",
    "        dataloader_num_workers=64,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"F1 score\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"none\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3_SyzasCQZy"
   },
   "source": [
    "## Self Distillation Trainer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XyJR66QCUeW"
   },
   "outputs": [],
   "source": [
    "     trainer = SelfDistillationTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_encoded,\n",
    "        eval_dataset=val_encoded,\n",
    "        alpha=0.5,\n",
    "        temperature=2.0,\n",
    "        use_ema_teacher=True,\n",
    "        ema_decay=0.995,\n",
    "        callbacks=[system_metrics_callback, loss_metrics_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFXxYVwJXHIX"
   },
   "source": [
    "## Knowledge Distillation Trainer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRmmS2WrlsOu",
    "outputId": "31654c43-1c2e-4624-bc76-f77faf8c099b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-pruning\n",
      "  Downloading torch_pruning-1.5.2-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-pruning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-pruning) (3.0.2)\n",
      "Downloading torch_pruning-1.5.2-py3-none-any.whl (64 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-pruning\n",
      "Successfully installed torch-pruning-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciKa9Qksl2r-",
    "outputId": "c8309eaf-86cb-4c8a-bd4f-cf267dacd0d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=24, bias=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "prune.ln_structured(\n",
    "    module=teacher_model.classifier,\n",
    "    name=\"weight\",\n",
    "    amount=0.2,\n",
    "    n=1,\n",
    "    dim=1\n",
    ")\n",
    "prune.remove(teacher_model.classifier, \"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smPbX5z_EpE5",
    "outputId": "23771e35-c405-4848-ca82-cad193252617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model_fp16 = teacher_model.half()\n",
    "teacher_model_fp16.eval()\n",
    "teacher_model_fp16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEicxFK50Nup"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config_int4 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "\n",
    "teacher_model_int4 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_model_name, quantization_config=bnb_config_int4, device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_ZIsKd6l-2t",
    "outputId": "84e65815-2383-47a2-a592-c905ed7c4678"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model_int4.eval()\n",
    "teacher_model_int4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDkr62jdXM5J"
   },
   "outputs": [],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    teacher_model=teacher_model_int4,\n",
    "    alpha=0.5,\n",
    "    temperature=2.0,\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encoded,\n",
    "    eval_dataset=val_encoded,\n",
    "    callbacks=[system_metrics_callback, loss_metrics_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-Y9B209YLKt"
   },
   "source": [
    "## Metrics Computation (Accuracy, Precision, Recall, FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlyGazd9YSZ-"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1 score\": f1\n",
    "    }\n",
    "\n",
    "trainer.compute_metrics = compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhpPGvyGJvHG"
   },
   "source": [
    "## Student Model Self Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "YfOkDntEqamo",
    "outputId": "ef03498f-5172-4c0a-b78c-9370345530c0"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10956' max='19800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10956/19800 1:39:52 < 1:20:38, 1.83 it/s, Epoch 2.77/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.991887</td>\n",
       "      <td>0.975681</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.949857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.018013</td>\n",
       "      <td>0.992244</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.954959</td>\n",
       "      <td>0.960872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19800' max='19800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19800/19800 3:07:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.991887</td>\n",
       "      <td>0.975681</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.949857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.018013</td>\n",
       "      <td>0.992244</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.954959</td>\n",
       "      <td>0.960872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.016716</td>\n",
       "      <td>0.992559</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.963919</td>\n",
       "      <td>0.966288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.992751</td>\n",
       "      <td>0.965390</td>\n",
       "      <td>0.959998</td>\n",
       "      <td>0.961631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.961226</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.962923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19800, training_loss=0.014812141998548701, metrics={'train_runtime': 11268.7528, 'train_samples_per_second': 527.024, 'train_steps_per_second': 1.757, 'total_flos': 1.7066696635957248e+17, 'train_loss': 0.014812141998548701, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "SM-1Uk-zUlqf",
    "outputId": "831b7bf1-53bd-4403-ad8c-603ff36f666e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4361' max='19800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4361/19800 40:46 < 2:24:25, 1.78 it/s, Epoch 1.10/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>0.991235</td>\n",
       "      <td>0.932478</td>\n",
       "      <td>0.915458</td>\n",
       "      <td>0.918511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k2DnHlIyJzkf",
    "outputId": "277e731f-b3e7-4634-9947-45419e74dc77"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13533' max='23760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13533/23760 1:25:42 < 1:04:46, 2.63 it/s, Epoch 5.70/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.020882</td>\n",
       "      <td>0.991466</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.930756</td>\n",
       "      <td>0.929811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.991781</td>\n",
       "      <td>0.930840</td>\n",
       "      <td>0.930627</td>\n",
       "      <td>0.928890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.991887</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>0.942297</td>\n",
       "      <td>0.946796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>0.935082</td>\n",
       "      <td>0.920001</td>\n",
       "      <td>0.924537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.992292</td>\n",
       "      <td>0.962527</td>\n",
       "      <td>0.959508</td>\n",
       "      <td>0.960313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23760' max='23760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23760/23760 2:32:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.020882</td>\n",
       "      <td>0.991466</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.930756</td>\n",
       "      <td>0.929811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.991781</td>\n",
       "      <td>0.930840</td>\n",
       "      <td>0.930627</td>\n",
       "      <td>0.928890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.991887</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>0.942297</td>\n",
       "      <td>0.946796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>0.935082</td>\n",
       "      <td>0.920001</td>\n",
       "      <td>0.924537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.992292</td>\n",
       "      <td>0.962527</td>\n",
       "      <td>0.959508</td>\n",
       "      <td>0.960313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.992433</td>\n",
       "      <td>0.969409</td>\n",
       "      <td>0.960308</td>\n",
       "      <td>0.962992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>0.992472</td>\n",
       "      <td>0.970082</td>\n",
       "      <td>0.959027</td>\n",
       "      <td>0.962739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.966070</td>\n",
       "      <td>0.966253</td>\n",
       "      <td>0.964981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.992692</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>0.967659</td>\n",
       "      <td>0.971143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.992732</td>\n",
       "      <td>0.963149</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.964570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23760, training_loss=0.015710366655592667, metrics={'train_runtime': 9134.0624, 'train_samples_per_second': 1300.386, 'train_steps_per_second': 2.601, 'total_flos': 3.4133393271914496e+17, 'train_loss': 0.015710366655592667, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH8PzTL5YYuu"
   },
   "source": [
    "## Student Model Training && Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vEQwnI4omLFe",
    "outputId": "2dc1348d-3488-4469-eff5-844911f8dd78"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27639' max='36560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27639/36560 4:41:52 < 1:30:59, 1.63 it/s, Epoch 15.12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.185933</td>\n",
       "      <td>0.977460</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>0.781113</td>\n",
       "      <td>0.779659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.984355</td>\n",
       "      <td>0.914213</td>\n",
       "      <td>0.842124</td>\n",
       "      <td>0.840406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.913595</td>\n",
       "      <td>0.866189</td>\n",
       "      <td>0.869935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.077892</td>\n",
       "      <td>0.988213</td>\n",
       "      <td>0.920653</td>\n",
       "      <td>0.890219</td>\n",
       "      <td>0.895336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.067743</td>\n",
       "      <td>0.989439</td>\n",
       "      <td>0.924572</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>0.907319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.059853</td>\n",
       "      <td>0.989915</td>\n",
       "      <td>0.925853</td>\n",
       "      <td>0.910291</td>\n",
       "      <td>0.911786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>0.928434</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.915615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.990559</td>\n",
       "      <td>0.921071</td>\n",
       "      <td>0.918535</td>\n",
       "      <td>0.916199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>0.991121</td>\n",
       "      <td>0.931790</td>\n",
       "      <td>0.918502</td>\n",
       "      <td>0.921662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.991239</td>\n",
       "      <td>0.935317</td>\n",
       "      <td>0.917813</td>\n",
       "      <td>0.923191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.991423</td>\n",
       "      <td>0.926390</td>\n",
       "      <td>0.923345</td>\n",
       "      <td>0.921256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.991679</td>\n",
       "      <td>0.933087</td>\n",
       "      <td>0.921111</td>\n",
       "      <td>0.924441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.991824</td>\n",
       "      <td>0.978195</td>\n",
       "      <td>0.928229</td>\n",
       "      <td>0.936573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.041371</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>0.935889</td>\n",
       "      <td>0.922555</td>\n",
       "      <td>0.925282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.041655</td>\n",
       "      <td>0.991961</td>\n",
       "      <td>0.978485</td>\n",
       "      <td>0.928836</td>\n",
       "      <td>0.936984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36560' max='36560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36560/36560 6:13:18, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.185933</td>\n",
       "      <td>0.977460</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>0.781113</td>\n",
       "      <td>0.779659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.984355</td>\n",
       "      <td>0.914213</td>\n",
       "      <td>0.842124</td>\n",
       "      <td>0.840406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.913595</td>\n",
       "      <td>0.866189</td>\n",
       "      <td>0.869935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.077892</td>\n",
       "      <td>0.988213</td>\n",
       "      <td>0.920653</td>\n",
       "      <td>0.890219</td>\n",
       "      <td>0.895336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.067743</td>\n",
       "      <td>0.989439</td>\n",
       "      <td>0.924572</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>0.907319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.059853</td>\n",
       "      <td>0.989915</td>\n",
       "      <td>0.925853</td>\n",
       "      <td>0.910291</td>\n",
       "      <td>0.911786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>0.928434</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.915615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.990559</td>\n",
       "      <td>0.921071</td>\n",
       "      <td>0.918535</td>\n",
       "      <td>0.916199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>0.991121</td>\n",
       "      <td>0.931790</td>\n",
       "      <td>0.918502</td>\n",
       "      <td>0.921662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.991239</td>\n",
       "      <td>0.935317</td>\n",
       "      <td>0.917813</td>\n",
       "      <td>0.923191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.991423</td>\n",
       "      <td>0.926390</td>\n",
       "      <td>0.923345</td>\n",
       "      <td>0.921256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.991679</td>\n",
       "      <td>0.933087</td>\n",
       "      <td>0.921111</td>\n",
       "      <td>0.924441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.991824</td>\n",
       "      <td>0.978195</td>\n",
       "      <td>0.928229</td>\n",
       "      <td>0.936573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.041371</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>0.935889</td>\n",
       "      <td>0.922555</td>\n",
       "      <td>0.925282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.041655</td>\n",
       "      <td>0.991961</td>\n",
       "      <td>0.978485</td>\n",
       "      <td>0.928836</td>\n",
       "      <td>0.936984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.040373</td>\n",
       "      <td>0.992056</td>\n",
       "      <td>0.976767</td>\n",
       "      <td>0.943718</td>\n",
       "      <td>0.951846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.992213</td>\n",
       "      <td>0.978889</td>\n",
       "      <td>0.931943</td>\n",
       "      <td>0.938637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.992217</td>\n",
       "      <td>0.980102</td>\n",
       "      <td>0.942836</td>\n",
       "      <td>0.953306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.038347</td>\n",
       "      <td>0.992335</td>\n",
       "      <td>0.980229</td>\n",
       "      <td>0.943627</td>\n",
       "      <td>0.954174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>0.992319</td>\n",
       "      <td>0.979620</td>\n",
       "      <td>0.937388</td>\n",
       "      <td>0.947005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36560, training_loss=0.10100663633654362, metrics={'train_runtime': 22402.5685, 'train_samples_per_second': 1060.397, 'train_steps_per_second': 1.632, 'total_flos': 6.826678654382899e+17, 'train_loss': 0.10100663633654362, 'epoch': 20.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rdoL5OtdmAKd",
    "outputId": "b6d21511-d4c8-447c-dd1b-317fdf7b8bb8"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29640' max='36560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29640/36560 5:06:14 < 1:11:30, 1.61 it/s, Epoch 16.21/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.122835</td>\n",
       "      <td>0.982992</td>\n",
       "      <td>0.865848</td>\n",
       "      <td>0.839166</td>\n",
       "      <td>0.834319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.088350</td>\n",
       "      <td>0.986461</td>\n",
       "      <td>0.910994</td>\n",
       "      <td>0.867245</td>\n",
       "      <td>0.865174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.076322</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.915228</td>\n",
       "      <td>0.886933</td>\n",
       "      <td>0.888187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.988885</td>\n",
       "      <td>0.925249</td>\n",
       "      <td>0.896571</td>\n",
       "      <td>0.900693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.056788</td>\n",
       "      <td>0.989671</td>\n",
       "      <td>0.927220</td>\n",
       "      <td>0.902631</td>\n",
       "      <td>0.907466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.920216</td>\n",
       "      <td>0.915570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.046033</td>\n",
       "      <td>0.990877</td>\n",
       "      <td>0.928216</td>\n",
       "      <td>0.922824</td>\n",
       "      <td>0.924748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>0.921899</td>\n",
       "      <td>0.920804</td>\n",
       "      <td>0.919607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>0.925272</td>\n",
       "      <td>0.925763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.991294</td>\n",
       "      <td>0.926935</td>\n",
       "      <td>0.931520</td>\n",
       "      <td>0.928829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.039702</td>\n",
       "      <td>0.991631</td>\n",
       "      <td>0.926421</td>\n",
       "      <td>0.935904</td>\n",
       "      <td>0.930805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>0.991891</td>\n",
       "      <td>0.933551</td>\n",
       "      <td>0.930666</td>\n",
       "      <td>0.930805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.037422</td>\n",
       "      <td>0.992095</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>0.933998</td>\n",
       "      <td>0.932012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.992091</td>\n",
       "      <td>0.931302</td>\n",
       "      <td>0.937585</td>\n",
       "      <td>0.933758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.992476</td>\n",
       "      <td>0.931936</td>\n",
       "      <td>0.938910</td>\n",
       "      <td>0.934932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.035111</td>\n",
       "      <td>0.992382</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.937634</td>\n",
       "      <td>0.934719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36560' max='36560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36560/36560 6:18:18, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.122835</td>\n",
       "      <td>0.982992</td>\n",
       "      <td>0.865848</td>\n",
       "      <td>0.839166</td>\n",
       "      <td>0.834319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.088350</td>\n",
       "      <td>0.986461</td>\n",
       "      <td>0.910994</td>\n",
       "      <td>0.867245</td>\n",
       "      <td>0.865174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.076322</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.915228</td>\n",
       "      <td>0.886933</td>\n",
       "      <td>0.888187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.988885</td>\n",
       "      <td>0.925249</td>\n",
       "      <td>0.896571</td>\n",
       "      <td>0.900693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.056788</td>\n",
       "      <td>0.989671</td>\n",
       "      <td>0.927220</td>\n",
       "      <td>0.902631</td>\n",
       "      <td>0.907466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.920216</td>\n",
       "      <td>0.915570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.046033</td>\n",
       "      <td>0.990877</td>\n",
       "      <td>0.928216</td>\n",
       "      <td>0.922824</td>\n",
       "      <td>0.924748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>0.921899</td>\n",
       "      <td>0.920804</td>\n",
       "      <td>0.919607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>0.925272</td>\n",
       "      <td>0.925763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.991294</td>\n",
       "      <td>0.926935</td>\n",
       "      <td>0.931520</td>\n",
       "      <td>0.928829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.039702</td>\n",
       "      <td>0.991631</td>\n",
       "      <td>0.926421</td>\n",
       "      <td>0.935904</td>\n",
       "      <td>0.930805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>0.991891</td>\n",
       "      <td>0.933551</td>\n",
       "      <td>0.930666</td>\n",
       "      <td>0.930805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.037422</td>\n",
       "      <td>0.992095</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>0.933998</td>\n",
       "      <td>0.932012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.992091</td>\n",
       "      <td>0.931302</td>\n",
       "      <td>0.937585</td>\n",
       "      <td>0.933758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.992476</td>\n",
       "      <td>0.931936</td>\n",
       "      <td>0.938910</td>\n",
       "      <td>0.934932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.035111</td>\n",
       "      <td>0.992382</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.937634</td>\n",
       "      <td>0.934719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>0.992370</td>\n",
       "      <td>0.942627</td>\n",
       "      <td>0.946155</td>\n",
       "      <td>0.942410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.954117</td>\n",
       "      <td>0.949434</td>\n",
       "      <td>0.950144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.034536</td>\n",
       "      <td>0.992625</td>\n",
       "      <td>0.951951</td>\n",
       "      <td>0.950079</td>\n",
       "      <td>0.950117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.992629</td>\n",
       "      <td>0.954576</td>\n",
       "      <td>0.951431</td>\n",
       "      <td>0.951474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36560, training_loss=0.05782456563814203, metrics={'train_runtime': 22701.9125, 'train_samples_per_second': 1046.415, 'train_steps_per_second': 1.61, 'total_flos': 6.826678654382899e+17, 'train_loss': 0.05782456563814203, 'epoch': 20.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nnut1JJSE3Ob",
    "outputId": "03926440-8d3f-4cee-db7c-45fd2f399d39"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23133' max='27420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23133/27420 3:58:01 < 44:06, 1.62 it/s, Epoch 12.65/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.182414</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>0.775922</td>\n",
       "      <td>0.778406</td>\n",
       "      <td>0.774197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.906047</td>\n",
       "      <td>0.852169</td>\n",
       "      <td>0.850208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.085464</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>0.913982</td>\n",
       "      <td>0.883320</td>\n",
       "      <td>0.885813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.070765</td>\n",
       "      <td>0.989125</td>\n",
       "      <td>0.920395</td>\n",
       "      <td>0.898158</td>\n",
       "      <td>0.902888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.989734</td>\n",
       "      <td>0.931262</td>\n",
       "      <td>0.898463</td>\n",
       "      <td>0.907024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.057230</td>\n",
       "      <td>0.990135</td>\n",
       "      <td>0.920596</td>\n",
       "      <td>0.913245</td>\n",
       "      <td>0.910573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.053413</td>\n",
       "      <td>0.990669</td>\n",
       "      <td>0.928429</td>\n",
       "      <td>0.915608</td>\n",
       "      <td>0.918715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.051073</td>\n",
       "      <td>0.990932</td>\n",
       "      <td>0.928669</td>\n",
       "      <td>0.918390</td>\n",
       "      <td>0.919907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.991125</td>\n",
       "      <td>0.973227</td>\n",
       "      <td>0.928382</td>\n",
       "      <td>0.934650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>0.991384</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>0.923748</td>\n",
       "      <td>0.934354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.045126</td>\n",
       "      <td>0.991545</td>\n",
       "      <td>0.972153</td>\n",
       "      <td>0.932254</td>\n",
       "      <td>0.936023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.042889</td>\n",
       "      <td>0.991734</td>\n",
       "      <td>0.975702</td>\n",
       "      <td>0.939485</td>\n",
       "      <td>0.947725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27420' max='27420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27420/27420 4:43:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.182414</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>0.775922</td>\n",
       "      <td>0.778406</td>\n",
       "      <td>0.774197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.906047</td>\n",
       "      <td>0.852169</td>\n",
       "      <td>0.850208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.085464</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>0.913982</td>\n",
       "      <td>0.883320</td>\n",
       "      <td>0.885813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.070765</td>\n",
       "      <td>0.989125</td>\n",
       "      <td>0.920395</td>\n",
       "      <td>0.898158</td>\n",
       "      <td>0.902888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.989734</td>\n",
       "      <td>0.931262</td>\n",
       "      <td>0.898463</td>\n",
       "      <td>0.907024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.057230</td>\n",
       "      <td>0.990135</td>\n",
       "      <td>0.920596</td>\n",
       "      <td>0.913245</td>\n",
       "      <td>0.910573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.053413</td>\n",
       "      <td>0.990669</td>\n",
       "      <td>0.928429</td>\n",
       "      <td>0.915608</td>\n",
       "      <td>0.918715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.051073</td>\n",
       "      <td>0.990932</td>\n",
       "      <td>0.928669</td>\n",
       "      <td>0.918390</td>\n",
       "      <td>0.919907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.991125</td>\n",
       "      <td>0.973227</td>\n",
       "      <td>0.928382</td>\n",
       "      <td>0.934650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>0.991384</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>0.923748</td>\n",
       "      <td>0.934354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.045126</td>\n",
       "      <td>0.991545</td>\n",
       "      <td>0.972153</td>\n",
       "      <td>0.932254</td>\n",
       "      <td>0.936023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.042889</td>\n",
       "      <td>0.991734</td>\n",
       "      <td>0.975702</td>\n",
       "      <td>0.939485</td>\n",
       "      <td>0.947725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.042570</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.975823</td>\n",
       "      <td>0.951409</td>\n",
       "      <td>0.959719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.042308</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.974269</td>\n",
       "      <td>0.946689</td>\n",
       "      <td>0.954236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.041908</td>\n",
       "      <td>0.991899</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0.946914</td>\n",
       "      <td>0.954612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=27420, training_loss=0.10546667625615407, metrics={'train_runtime': 17029.668, 'train_samples_per_second': 1046.216, 'train_steps_per_second': 1.61, 'total_flos': 5.1200089907871744e+17, 'train_loss': 0.10546667625615407, 'epoch': 15.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5-45KvCwYga2",
    "outputId": "9fc8e05c-cc09-4fed-bc1d-052a009d893d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27420' max='27420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27420/27420 4:39:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.132869</td>\n",
       "      <td>0.982670</td>\n",
       "      <td>0.872999</td>\n",
       "      <td>0.832117</td>\n",
       "      <td>0.830746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.103264</td>\n",
       "      <td>0.985345</td>\n",
       "      <td>0.869651</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.852904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.082014</td>\n",
       "      <td>0.987872</td>\n",
       "      <td>0.920866</td>\n",
       "      <td>0.879031</td>\n",
       "      <td>0.878888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.989266</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.895283</td>\n",
       "      <td>0.898007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.063718</td>\n",
       "      <td>0.989828</td>\n",
       "      <td>0.920434</td>\n",
       "      <td>0.902409</td>\n",
       "      <td>0.901652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.059522</td>\n",
       "      <td>0.990072</td>\n",
       "      <td>0.920634</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.905146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.053832</td>\n",
       "      <td>0.990736</td>\n",
       "      <td>0.927285</td>\n",
       "      <td>0.908439</td>\n",
       "      <td>0.909967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.051810</td>\n",
       "      <td>0.990948</td>\n",
       "      <td>0.926575</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>0.912302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.049212</td>\n",
       "      <td>0.991085</td>\n",
       "      <td>0.935222</td>\n",
       "      <td>0.910492</td>\n",
       "      <td>0.914794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.046301</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>0.933451</td>\n",
       "      <td>0.915289</td>\n",
       "      <td>0.918463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>0.991427</td>\n",
       "      <td>0.928219</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.916890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.991628</td>\n",
       "      <td>0.932788</td>\n",
       "      <td>0.919024</td>\n",
       "      <td>0.920359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.935810</td>\n",
       "      <td>0.917992</td>\n",
       "      <td>0.921679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.042908</td>\n",
       "      <td>0.991773</td>\n",
       "      <td>0.934561</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.921376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.042357</td>\n",
       "      <td>0.991867</td>\n",
       "      <td>0.934826</td>\n",
       "      <td>0.921530</td>\n",
       "      <td>0.923802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=27420, training_loss=0.07269379259851359, metrics={'train_runtime': 16785.0763, 'train_samples_per_second': 1061.462, 'train_steps_per_second': 1.634, 'total_flos': 5.1200089907871744e+17, 'train_loss': 0.07269379259851359, 'epoch': 15.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IoKPIw4-Vmj",
    "outputId": "1d62e72b-2fc7-4db8-9705-7cc0aa789e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 20 14:33:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   65C    P0             32W /   72W |   20981MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxZRAPDT_chu"
   },
   "source": [
    "## Student Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "referenced_widgets": [
      "fbea6ba99beb41db86edfb66cbd871e2",
      "1ed3e38e05284a41a7fa7845244b671d",
      "8be36a57300c413181e67b7dab494833",
      "963393099d8a4ba6b14cff4f2eb9203c",
      "63af796d17644033a59309bde8f981ae",
      "8bc4baba90f54389aab8fa9b337ecfd6",
      "4fd44952bd574f479a4e5839d356895b",
      "159ad2eb8f86475f8d9005bd99f6d365",
      "a8966a6ea4b8457b9d9054711b037557",
      "560327488b7545b0ac9b59c43c44c9ab",
      "87cf5676a0964a74bb7c4c6a11a51a50",
      "8718e81aae5146e795c9ed3b85df58b6",
      "ee9b9c344f504609b3fcf3cd445e5b0c",
      "c5be430ceb9f4ebcab927c56cb5d188b",
      "1eaefa3c989f4c798a42b4b33f12538b",
      "61c50c86eae2473e8876a9e97344e065",
      "3d6f05d9b9044397a5fa019e1d90eb79",
      "2439b52b666049e1aab93d5950b126e3",
      "77fd2a7ba70d41e68930a041f890699b",
      "f098bf6d36ab4254b27f79f80ab7b9a8",
      "85d8f4f6589b44228c21a7f8c11b6f38",
      "71eeb6ad3b3e485ba1423361749273b3",
      "7719fe810ac34606adff405185ad29c4",
      "34066635fff54bcda171457c65f6ff93",
      "41d621eeba1d4979953fea72bd6b96eb",
      "0bf64d66edc94f7895b9d9a26acba62b",
      "43ccc3fca9db4437ba0030da9611d2a7",
      "a14cbe30dd784b0fb4cbf7d5e7983afa",
      "47fb00cb0f764db981ee79f56aa8a388",
      "08c44543eec341769d190881892b6b3d",
      "65b504992ba94e24865fb351f15dc256",
      "9a89c013b7e24e8f9bd8da06f62dbf83",
      "a2fcdccc7508498196492cabab2a90e3",
      "2c62cccc2c624e618506ba4fcd700187",
      "f2dac1a90a0e4807854f2e10a1d72e0b",
      "c10e9fc6d3734bacb3f20899a51d7997",
      "d528db81449a4d06ac6119968830b40e",
      "7736f7bbd5974977bb9ad607e00ea336",
      "bc36fb6abf634959a8f04673ee20e565",
      "ec5ad951095c408e8c5ef1c0417c52a8",
      "40e88d39bc4f4ed4967a3eb35e54d5e2",
      "89a991603cee47d88cf06c56f3e3c0f4",
      "9fc20d1f95f64318917f78b62d6294ac",
      "9833d1c40169471dbbd8fc6cf630786e"
     ]
    },
    "id": "PRsK-zX55zx-",
    "outputId": "0182028f-3616-4f00-e04c-f7d5ce61613b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbea6ba99beb41db86edfb66cbd871e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8718e81aae5146e795c9ed3b85df58b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7719fe810ac34606adff405185ad29c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/76.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c62cccc2c624e618506ba4fcd700187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/gates04/Structured-FP16-KD-SD-new-NID/commit/d1c0354001b2267745c861c4c882164aa3ad9271', commit_message='Student Model Tokenizer', commit_description='', oid='d1c0354001b2267745c861c4c882164aa3ad9271', pr_url=None, repo_url=RepoUrl('https://huggingface.co/gates04/Structured-FP16-KD-SD-new-NID', endpoint='https://huggingface.co', repo_type='model', repo_id='gates04/Structured-FP16-KD-SD-new-NID'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "login(token=\"HUGGING_FACE_KEY\")\n",
    "\n",
    "trainer.push_to_hub()\n",
    "\n",
    "tokenizer.push_to_hub(repo_id=\"gates04/Structured-FP16-KD-SD-NID\", commit_message=\"Student Model Tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
